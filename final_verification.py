# final_verification.py
import torch
import warnings
warnings.filterwarnings("ignore")

def test_basic_imports():
    """ê¸°ë³¸ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” Testing basic imports...")
    
    try:
        from transformers import T5Tokenizer
        from models.connection_transformer import ConnectionTransformer
        from models.baseline_transformer import BaselineTransformer
        from training.trainer import Trainer
        from configs.strategyqa_config import get_config
        print("âœ… All imports successful")
        return True
    except Exception as e:
        print(f"âŒ Import failed: {e}")
        return False

def test_model_creation():
    """ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Testing model creation...")
    
    try:
        from models.connection_transformer import ConnectionTransformer
        from models.baseline_transformer import BaselineTransformer
        
        # ì‘ì€ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸
        vocab_size = 1000
        
        # Connection Transformer
        conn_model = ConnectionTransformer(
            vocab_size=vocab_size,
            d_model=32,
            num_slots=8,
            bilinear_rank=2,
            max_reasoning_steps=1,
            max_seq_len=16,
            pad_token_id=0
        )
        
        # Baseline Transformer
        baseline_model = BaselineTransformer(
            vocab_size=vocab_size,
            d_model=32,
            num_layers=2,
            ffn_multiplier=2,
            max_seq_len=16,
            pad_token_id=0
        )
        
        # Forward pass í…ŒìŠ¤íŠ¸
        input_ids = torch.randint(0, vocab_size, (2, 8))
        attention_mask = torch.ones(2, 8, dtype=torch.bool)
        
        with torch.no_grad():
            conn_output = conn_model(input_ids, attention_mask)
            baseline_output = baseline_model(input_ids, attention_mask)
            
            print(f"   Connection output: {conn_output.shape}")
            print(f"   Baseline output: {baseline_output.shape}")
        
        print("âœ… Model creation tests passed")
        return True
        
    except Exception as e:
        print(f"âŒ Model test failed: {e}")
        return False

def test_config_system():
    """ì„¤ì • ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Testing config system...")
    
    try:
        from configs.strategyqa_config import get_config
        from configs.logiqa_config import get_config as logiqa_get_config
        
        # ë‹¤ì–‘í•œ í¬ê¸° í…ŒìŠ¤íŠ¸
        config_nano = get_config("nano")
        config_micro = logiqa_get_config("micro")
        
        # í•„ìˆ˜ ì†ì„± í™•ì¸
        required = ['d_model', 'num_slots', 'bilinear_rank', 'learning_rate']
        for attr in required:
            assert hasattr(config_nano, attr), f"Missing {attr}"
            assert hasattr(config_micro, attr), f"Missing {attr}"
        
        print(f"   Nano config: d_model={config_nano.d_model}")
        print(f"   Micro config: d_model={config_micro.d_model}")
        print("âœ… Config system tests passed")
        return True
        
    except Exception as e:
        print(f"âŒ Config test failed: {e}")
        return False

def test_training_setup():
    """í›ˆë ¨ ì„¤ì • í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Testing training setup...")
    
    try:
        from training.trainer import Trainer
        from models.connection_transformer import ConnectionTransformer
        from configs.strategyqa_config import get_config
        from transformers import T5Tokenizer
        
        config = get_config("nano")
        tokenizer = T5Tokenizer.from_pretrained("t5-base")
        
        model = ConnectionTransformer(
            vocab_size=tokenizer.vocab_size,
            d_model=config.d_model,
            num_slots=config.num_slots,
            bilinear_rank=config.bilinear_rank,
            max_reasoning_steps=config.max_reasoning_steps,
            max_seq_len=config.max_seq_len,
            pad_token_id=tokenizer.pad_token_id
        )
        
        trainer = Trainer(model, config, model_type="connection")
        trainer.set_tokenizer(tokenizer)
        
        print(f"   Trainer device: {trainer.device}")
        print(f"   Model parameters: {sum(p.numel() for p in model.parameters()):,}")
        print("âœ… Training setup tests passed")
        return True
        
    except Exception as e:
        print(f"âŒ Training setup test failed: {e}")
        return False

def main():
    """ì „ì²´ ê²€ì¦ ì‹¤í–‰"""
    print("ğŸš€ Connection Transformer Quick Verification")
    print("=" * 50)
    
    tests = [
        ("Basic Imports", test_basic_imports),
        ("Model Creation", test_model_creation),
        ("Config System", test_config_system),
        ("Training Setup", test_training_setup)
    ]
    
    results = {}
    for name, test_func in tests:
        results[name] = test_func()
    
    print("\n" + "=" * 50)
    print("ğŸ“‹ Verification Results")
    print("=" * 50)
    
    for name, success in results.items():
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"{name:20}: {status}")
    
    all_passed = all(results.values())
    if all_passed:
        print("\nğŸ‰ All tests passed! Ready to run experiments.")
        print("\nğŸ“‹ Quick start:")
        print("   python main.py --dataset strategyqa --model connection --model_size nano")
    else:
        print("\nâš ï¸ Some tests failed. Check your environment.")
    
    return all_passed

if __name__ == "__main__":
    main()