# final_verification.py - ê°„ë‹¨í•œ ì‹œìŠ¤í…œ ê²€ì¦
import torch
import warnings
warnings.filterwarnings("ignore")

def test_imports():
    """í•„ìˆ˜ ëª¨ë“ˆ import í…ŒìŠ¤íŠ¸"""
    print("ğŸ” Testing imports...")
    
    try:
        from transformers import T5Tokenizer
        from models.connection_transformer import ConnectionTransformer
        from models.baseline_transformer import BaselineTransformer
        from training.trainer import Trainer
        from configs.strategyqa_config import get_config
        print("âœ… Imports successful")
        return True
    except Exception as e:
        print(f"âŒ Import failed: {e}")
        return False

def test_models():
    """ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Testing models...")
    
    try:
        from transformers import T5Tokenizer
        from models.connection_transformer import ConnectionTransformer
        from models.baseline_transformer import BaselineTransformer
        
        tokenizer = T5Tokenizer.from_pretrained("t5-base")
        vocab_size = tokenizer.vocab_size
        
        # Connection model
        conn_model = ConnectionTransformer(
            src_vocab_size=vocab_size, tgt_vocab_size=vocab_size,
            d_model=32, num_slots=8, bilinear_rank=2,
            max_reasoning_steps=1, max_seq_len=16,
            src_pad_token_id=0, tgt_pad_token_id=0,
            num_decoder_layers=2, num_heads=2
        )
        
        # Baseline model
        baseline_model = BaselineTransformer(
            src_vocab_size=vocab_size, tgt_vocab_size=vocab_size,
            d_model=32, num_encoder_layers=2, num_decoder_layers=2,
            ffn_multiplier=2, max_seq_len=16,
            src_pad_token_id=0, tgt_pad_token_id=0
        )
        
        # Quick forward test
        src_ids = torch.randint(1, 1000, (1, 4))
        tgt_ids = torch.randint(1, 1000, (1, 3))
        src_mask = torch.ones(1, 4, dtype=torch.bool)
        tgt_mask = torch.ones(1, 3, dtype=torch.bool)
        
        with torch.no_grad():
            conn_out = conn_model(src_ids, tgt_ids, src_mask, tgt_mask)
            base_out = baseline_model(src_ids, tgt_ids, src_mask, tgt_mask)
        
        print(f"   Connection output: {conn_out.shape}")
        print(f"   Baseline output: {base_out.shape}")
        print("âœ… Models working")
        return True
        
    except Exception as e:
        print(f"âŒ Model test failed: {e}")
        return False

def test_configs():
    """ì„¤ì • ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Testing configs...")
    
    try:
        from configs.strategyqa_config import get_config
        
        config = get_config("nano")
        
        # Basic attributes
        assert hasattr(config, 'd_model')
        assert hasattr(config, 'num_slots')
        assert hasattr(config, 'learning_rate')
        
        print(f"   Config d_model: {config.d_model}")
        print("âœ… Configs working")
        return True
        
    except Exception as e:
        print(f"âŒ Config test failed: {e}")
        return False

def test_training():
    """í›ˆë ¨ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Testing training...")
    
    try:
        from training.trainer import Trainer
        from models.connection_transformer import ConnectionTransformer
        from configs.strategyqa_config import get_config
        from transformers import T5Tokenizer
        
        config = get_config("nano")
        tokenizer = T5Tokenizer.from_pretrained("t5-base")
        
        model = ConnectionTransformer(
            src_vocab_size=tokenizer.vocab_size,
            tgt_vocab_size=tokenizer.vocab_size,
            d_model=config.d_model,
            num_slots=config.num_slots,
            bilinear_rank=config.bilinear_rank,
            max_reasoning_steps=config.max_reasoning_steps,
            max_seq_len=config.max_seq_len,
            src_pad_token_id=tokenizer.pad_token_id,
            tgt_pad_token_id=tokenizer.pad_token_id,
            num_decoder_layers=2,
            num_heads=2
        )
        
        trainer = Trainer(model, config, model_type="connection")
        trainer.set_tokenizer(tokenizer)
        
        print(f"   Trainer device: {trainer.device}")
        print("âœ… Training setup working")
        return True
        
    except Exception as e:
        print(f"âŒ Training test failed: {e}")
        return False

def main():
    """ê°„ë‹¨í•œ ê²€ì¦ ì‹¤í–‰"""
    print("ğŸš€ Connection Transformer Quick Check")
    print("="*40)
    
    tests = [
        ("Imports", test_imports),
        ("Models", test_models),
        ("Configs", test_configs),
        ("Training", test_training)
    ]
    
    results = {}
    for name, test_func in tests:
        results[name] = test_func()
    
    print("\n" + "="*40)
    print("ğŸ“‹ Results")
    print("="*40)
    
    for name, success in results.items():
        status = "âœ…" if success else "âŒ"
        print(f"{name:10}: {status}")
    
    all_passed = all(results.values())
    
    if all_passed:
        print("\nğŸ‰ All tests passed!")
        print("\nTry: python main.py --dataset strategyqa --model connection --model_size nano")
    else:
        print("\nâš ï¸ Some tests failed. Check your setup.")
    
    return all_passed

if __name__ == "__main__":
    main()