# final_verification.py - ìµœì¢… ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
"""
ìˆ˜ì •ëœ ëª¨ë“  íŒŒì¼ì˜ í†µí•© ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
"""
import torch
import warnings
warnings.filterwarnings("ignore")

def test_corrected_tokenizer():
    """ìˆ˜ì •ëœ í† í¬ë‚˜ì´ì € í…ŒìŠ¤íŠ¸"""
    print("ğŸ” Testing corrected tokenizer...")
    
    try:
        from transformers import T5Tokenizer
        
        tokenizer = T5Tokenizer.from_pretrained("t5-base")
        
        # T5 íŠ¹í™” í…ŒìŠ¤íŠ¸
        test_inputs = [
            "reason: The sky is blue. question: What color is the sky?",
            "solve: John has 5 apples. He gives 2 to Mary. How many does he have left?",
            "strategy: Can a person fly without any tools?"
        ]
        
        for input_text in test_inputs:
            # í† í¬ë‚˜ì´ì§•
            inputs = tokenizer(input_text, return_tensors="pt", padding="max_length", 
                             truncation=True, max_length=128)
            
            # ë””ì½”ë”©
            decoded = tokenizer.decode(inputs.input_ids[0], skip_special_tokens=True)
            
            print(f"   âœ… '{input_text[:30]}...' -> {inputs.input_ids.shape}")
        
        print("âœ… Tokenizer tests passed")
        return True
        
    except Exception as e:
        print(f"âŒ Tokenizer test failed: {e}")
        return False

def test_corrected_datasets():
    """ìˆ˜ì •ëœ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Testing corrected datasets...")
    
    try:
        from dataset.tokenizer_utils import get_tokenizer_and_dataset
        from configs.logiqa_config import get_config
        
        config = get_config("base")
        
        # LogiQA í…ŒìŠ¤íŠ¸
        try:
            tokenizer, train_dataset, eval_dataset = get_tokenizer_and_dataset("logiqa", config)
            
            # ì²« ë²ˆì§¸ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸
            sample = train_dataset[0]
            required_keys = ['input_ids', 'attention_mask', 'labels', 'target_text']
            
            for key in required_keys:
                if key not in sample:
                    raise ValueError(f"Missing key: {key}")
            
            print(f"   âœ… LogiQA: {len(train_dataset)} train, {len(eval_dataset)} eval")
            print(f"      Sample shapes: input_ids={sample['input_ids'].shape}, labels={sample['labels'].shape}")
            
        except Exception as e:
            print(f"   âš ï¸ LogiQA test failed: {e}")
        
        print("âœ… Dataset tests completed")
        return True
        
    except Exception as e:
        print(f"âŒ Dataset test failed: {e}")
        return False

def test_corrected_models():
    """ìˆ˜ì •ëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Testing corrected models...")
    
    try:
        from models.connection_transformer import ConnectionTransformer
        from models.baseline_transformer import BaselineTransformer
        
        # í…ŒìŠ¤íŠ¸ ì„¤ì •
        vocab_size = 32128  # T5-base vocab size
        d_model = 256
        num_slots = 128
        bilinear_rank = 32
        
        # Connection Transformer í…ŒìŠ¤íŠ¸
        conn_model = ConnectionTransformer(
            vocab_size=vocab_size,
            d_model=d_model,
            num_slots=num_slots,
            bilinear_rank=bilinear_rank,
            max_reasoning_steps=4,
            max_seq_len=128,
            pad_token_id=0
        )
        
        # Baseline Transformer í…ŒìŠ¤íŠ¸
        baseline_model = BaselineTransformer(
            vocab_size=vocab_size,
            d_model=d_model,
            num_layers=4,
            ffn_multiplier=4,
            max_seq_len=128,
            pad_token_id=0
        )
        
        # Forward pass í…ŒìŠ¤íŠ¸
        batch_size = 2
        seq_len = 10
        input_ids = torch.randint(0, vocab_size, (batch_size, seq_len))
        attention_mask = torch.ones(batch_size, seq_len, dtype=torch.bool)
        
        with torch.no_grad():
            # Connection Transformer
            conn_output = conn_model(input_ids, attention_mask)
            print(f"   âœ… Connection Transformer output: {conn_output.shape}")
            
            # Baseline Transformer
            baseline_output = baseline_model(input_ids, attention_mask)
            print(f"   âœ… Baseline Transformer output: {baseline_output.shape}")
            
            # Reasoning trace í…ŒìŠ¤íŠ¸
            conn_output_with_trace = conn_model(input_ids, attention_mask, return_reasoning_trace=True)
            logits, reasoning_info = conn_output_with_trace
            print(f"   âœ… Reasoning trace: {reasoning_info['actual_steps']} steps")
        
        print("âœ… Model tests passed")
        return True
        
    except Exception as e:
        print(f"âŒ Model test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_corrected_training():
    """ìˆ˜ì •ëœ í›ˆë ¨ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Testing corrected training setup...")
    
    try:
        from training.trainer import Trainer
        from models.connection_transformer import ConnectionTransformer
        from configs.logiqa_config import get_config
        from transformers import T5Tokenizer
        
        # ì„¤ì • ë° í† í¬ë‚˜ì´ì €
        config = get_config("base")
        tokenizer = T5Tokenizer.from_pretrained("t5-base")
        
        # ê°„ë‹¨í•œ ëª¨ë¸
        model = ConnectionTransformer(
            vocab_size=tokenizer.vocab_size,
            d_model=128,  # ì‘ê²Œ ì„¤ì •
            num_slots=64,
            bilinear_rank=16,
            max_reasoning_steps=2,
            max_seq_len=64,
            pad_token_id=tokenizer.pad_token_id
        )
        
        # Trainer ì´ˆê¸°í™”
        trainer = Trainer(model, config, model_type="connection")
        trainer.set_tokenizer(tokenizer)
        
        # ì†ì‹¤ ê³„ì‚° í…ŒìŠ¤íŠ¸
        batch_size = 2
        seq_len = 10
        vocab_size = tokenizer.vocab_size
        
        input_ids = torch.randint(0, vocab_size, (batch_size, seq_len))
        attention_mask = torch.ones(batch_size, seq_len, dtype=torch.bool)
        labels = torch.randint(0, vocab_size, (batch_size, seq_len))
        
        with torch.no_grad():
            logits, reasoning_info = model(input_ids, attention_mask, return_reasoning_trace=True)
            loss = trainer.calculate_loss(logits, labels, reasoning_info)
            
            print(f"   âœ… Loss calculation: {loss.item():.4f}")
            print(f"   âœ… Reasoning steps: {reasoning_info['actual_steps']}")
        
        print("âœ… Training tests passed")
        return True
        
    except Exception as e:
        print(f"âŒ Training test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ì „ì²´ ê²€ì¦ ì‹¤í–‰"""
    print("ğŸš€ Final Verification of Corrected Implementation")
    print("=" * 70)
    
    results = {}
    
    # 1. í† í¬ë‚˜ì´ì € ê²€ì¦
    results['tokenizer'] = test_corrected_tokenizer()
    
    # 2. ë°ì´í„°ì…‹ ê²€ì¦  
    results['datasets'] = test_corrected_datasets()
    
    # 3. ëª¨ë¸ ê²€ì¦
    results['models'] = test_corrected_models()
    
    # 4. í›ˆë ¨ ê²€ì¦
    results['training'] = test_corrected_training()
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 70)
    print("ğŸ“‹ Final Verification Results")
    print("=" * 70)
    
    for component, success in results.items():
        status = "âœ… í†µê³¼" if success else "âŒ ì‹¤íŒ¨"
        print(f"{component:15}: {status}")
    
    all_passed = all(results.values())
    if all_passed:
        print("\nğŸ‰ ëª¨ë“  ìˆ˜ì •ì‚¬í•­ ê²€ì¦ ì™„ë£Œ! êµ¬í˜„ì´ ì˜¬ë°”ë¦…ë‹ˆë‹¤.")
        print("\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
        print("   1. pip install -r requirements.txt")
        print("   2. python main.py --dataset logiqa --model connection")
        print("   3. python main.py --dataset logiqa --model baseline")
    else:
        print("\nâš ï¸ ì¼ë¶€ ê²€ì¦ ì‹¤íŒ¨. ë¬¸ì œì ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # ì‹¤íŒ¨í•œ í•­ëª©ë“¤ ìƒì„¸ ì•ˆë‚´
        failed_items = [k for k, v in results.items() if not v]
        print(f"\nì‹¤íŒ¨í•œ í•­ëª©: {', '.join(failed_items)}")
        
        if 'tokenizer' in failed_items:
            print("\nğŸ”§ í† í¬ë‚˜ì´ì € ë¬¸ì œ í•´ê²°ë°©ë²•:")
            print("   pip install sentencepiece>=0.1.97")
        
        if 'datasets' in failed_items:
            print("\nğŸ”§ ë°ì´í„°ì…‹ ë¬¸ì œ í•´ê²°ë°©ë²•:")
            print("   ì¸í„°ë„· ì—°ê²° í™•ì¸ ë° HuggingFace Hub ì ‘ê·¼ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸")
    
    return all_passed

if __name__ == "__main__":
    main()