# final_verification.py - í†µí•© ì‹œìŠ¤í…œ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
"""
í†µí•© ëª¨ë¸ ì‚¬ì´ì¦ˆ ì‹œìŠ¤í…œì˜ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
"""
import torch
import warnings
warnings.filterwarnings("ignore")

def test_tokenizer_system():
    """í† í¬ë‚˜ì´ì € ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” Testing tokenizer system...")
    
    try:
        from transformers import T5Tokenizer
        
        tokenizer = T5Tokenizer.from_pretrained("t5-base", legacy=False)
        
        # ëª¨ë“  ë°ì´í„°ì…‹ task prefix í…ŒìŠ¤íŠ¸
        test_inputs = [
            "reason: The sky is blue. question: What color is the sky?",  # LogiQA
            "solve: John has 5 apples. He gives 2 to Mary. How many does he have left?",  # GSM8K
            "strategy: Can a person fly without any tools?",  # StrategyQA
            "infer: premise: All birds can fly. hypothesis: Penguins can fly."  # MultiNLI
        ]
        
        for input_text in test_inputs:
            inputs = tokenizer(input_text, return_tensors="pt", padding="max_length", 
                             truncation=True, max_length=128)
            decoded = tokenizer.decode(inputs.input_ids[0], skip_special_tokens=True)
            print(f"   âœ… '{input_text[:30]}...' -> {inputs.input_ids.shape}")
        
        print("âœ… Tokenizer tests passed")
        return True
        
    except Exception as e:
        print(f"âŒ Tokenizer test failed: {e}")
        return False

def test_unified_configs():
    """í†µí•© ì„¤ì • ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Testing unified config system...")
    
    try:
        # ëª¨ë“  ë°ì´í„°ì…‹ ì„¤ì • í…ŒìŠ¤íŠ¸
        datasets_to_test = [
            ("logiqa", "micro"),
            ("gsm8k", "micro"), 
            ("strategyqa", "nano"),
            ("multinli", "base")  # í° ë°ì´í„°ì…‹
        ]
        
        for dataset_name, model_size in datasets_to_test:
            print(f"   Testing {dataset_name} with {model_size} model...")
            
            if dataset_name == "logiqa":
                from configs.logiqa_config import get_config
            elif dataset_name == "gsm8k":
                from configs.gsm8k_config import get_config
            elif dataset_name == "strategyqa":
                from configs.strategyqa_config import get_config
            elif dataset_name == "multinli":
                from configs.multinli_config import get_config
            
            config = get_config(model_size)
            
            # í•„ìˆ˜ ì†ì„± ì²´í¬
            required_attrs = [
                'dataset_name', 'd_model', 'num_slots', 'bilinear_rank',
                'max_reasoning_steps', 'learning_rate', 'batch_size', 
                'num_epochs', 'dropout', 'orthogonal_weight'
            ]
            
            for attr in required_attrs:
                if not hasattr(config, attr):
                    raise ValueError(f"Missing attribute: {attr}")
            
            # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚° í…ŒìŠ¤íŠ¸
            params = config.get_estimated_params()
            print(f"      âœ… {dataset_name}-{model_size}: {params['total']:,} params")
        
        print("âœ… Config system tests passed")
        return True
        
    except Exception as e:
        print(f"âŒ Config test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_dataset_loading():
    """ë°ì´í„°ì…‹ ë¡œë”© í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Testing dataset loading...")
    
    try:
        from dataset.tokenizer_utils import get_tokenizer_and_dataset
        
        # ê° ë°ì´í„°ì…‹ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (ì‘ì€ ëª¨ë¸ ì‚¬ìš©)
        test_configs = [
            ("logiqa", "micro"),
            ("strategyqa", "nano"),
            # ("multinli", "tiny"),  # ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ ì„ íƒì 
            # ("gsm8k", "micro")     # ì„ íƒì 
        ]
        
        for dataset_name, model_size in test_configs:
            print(f"   Testing {dataset_name} dataset loading...")
            
            # Config ê°€ì ¸ì˜¤ê¸°
            if dataset_name == "logiqa":
                from configs.logiqa_config import get_config
            elif dataset_name == "strategyqa":
                from configs.strategyqa_config import get_config
            
            config = get_config(model_size)
            
            try:
                tokenizer, train_dataset, eval_dataset = get_tokenizer_and_dataset(dataset_name, config)
                
                # ì²« ë²ˆì§¸ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸
                sample = train_dataset[0]
                required_keys = ['input_ids', 'attention_mask', 'labels', 'target_text']
                
                for key in required_keys:
                    if key not in sample:
                        raise ValueError(f"Missing key: {key}")
                
                print(f"      âœ… {dataset_name}: {len(train_dataset)} train, {len(eval_dataset)} eval")
                print(f"         Sample shapes: input_ids={sample['input_ids'].shape}, labels={sample['labels'].shape}")
                
            except Exception as e:
                print(f"      âš ï¸ {dataset_name} loading failed: {e}")
        
        print("âœ… Dataset loading tests completed")
        return True
        
    except Exception as e:
        print(f"âŒ Dataset loading test failed: {e}")
        return False

def test_model_architectures():
    """ëª¨ë¸ ì•„í‚¤í…ì²˜ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Testing model architectures...")
    
    try:
        from models.connection_transformer import ConnectionTransformer
        from models.baseline_transformer import BaselineTransformer
        
        # ë‹¤ì–‘í•œ ëª¨ë¸ ì‚¬ì´ì¦ˆ í…ŒìŠ¤íŠ¸
        test_configs = [
            {"d_model": 32, "num_slots": 8, "bilinear_rank": 2},    # nano
            {"d_model": 64, "num_slots": 16, "bilinear_rank": 4},   # micro
            {"d_model": 128, "num_slots": 32, "bilinear_rank": 8},  # tiny
        ]
        
        vocab_size = 32128
        
        for i, config in enumerate(test_configs):
            size_names = ["nano", "micro", "tiny"]
            size_name = size_names[i]
            
            print(f"   Testing {size_name} models...")
            
            # Connection Transformer í…ŒìŠ¤íŠ¸
            conn_model = ConnectionTransformer(
                vocab_size=vocab_size,
                d_model=config["d_model"],
                num_slots=config["num_slots"],
                bilinear_rank=config["bilinear_rank"],
                max_reasoning_steps=2,
                max_seq_len=64,
                pad_token_id=0
            )
            
            # Baseline Transformer í…ŒìŠ¤íŠ¸
            baseline_model = BaselineTransformer(
                vocab_size=vocab_size,
                d_model=config["d_model"],
                num_layers=2,
                ffn_multiplier=4,
                max_seq_len=64,
                pad_token_id=0
            )
            
            # Forward pass í…ŒìŠ¤íŠ¸
            batch_size = 2
            seq_len = 8
            input_ids = torch.randint(0, 1000, (batch_size, seq_len))  # ì‘ì€ vocabìœ¼ë¡œ í…ŒìŠ¤íŠ¸
            attention_mask = torch.ones(batch_size, seq_len, dtype=torch.bool)
            
            with torch.no_grad():
                # Connection Transformer
                conn_output = conn_model(input_ids, attention_mask)
                print(f"      âœ… Connection {size_name}: {conn_output.shape}")
                
                # Baseline Transformer
                baseline_output = baseline_model(input_ids, attention_mask)
                print(f"      âœ… Baseline {size_name}: {baseline_output.shape}")
                
                # Reasoning trace í…ŒìŠ¤íŠ¸
                conn_output_with_trace = conn_model(input_ids, attention_mask, return_reasoning_trace=True)
                logits, reasoning_info = conn_output_with_trace
                print(f"      âœ… Reasoning trace: {reasoning_info['actual_steps']} steps")
                
                # Orthogonal regularization í…ŒìŠ¤íŠ¸
                if hasattr(conn_model, 'lightweight_orthogonal_regularization_loss'):
                    orth_loss = conn_model.lightweight_orthogonal_regularization_loss()
                    print(f"      âœ… Orthogonal loss: {orth_loss.item():.4f}")
        
        print("âœ… Model architecture tests passed")
        return True
        
    except Exception as e:
        print(f"âŒ Model test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_training_integration():
    """í›ˆë ¨ í†µí•© í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” Testing training integration...")
    
    try:
        from training.trainer import Trainer
        from models.connection_transformer import ConnectionTransformer
        from configs.strategyqa_config import get_config
        from transformers import T5Tokenizer
        
        # ê°€ì¥ ì‘ì€ ì„¤ì •ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        config = get_config("nano")
        tokenizer = T5Tokenizer.from_pretrained("t5-base", legacy=False)
        
        # ë§¤ìš° ì‘ì€ ëª¨ë¸
        model = ConnectionTransformer(
            vocab_size=tokenizer.vocab_size,
            d_model=32,
            num_slots=8,
            bilinear_rank=2,
            max_reasoning_steps=1,
            max_seq_len=32,
            pad_token_id=tokenizer.pad_token_id
        )
        
        # Trainer ì´ˆê¸°í™”
        trainer = Trainer(model, config, model_type="connection")
        trainer.set_tokenizer(tokenizer)
        
        # ì†ì‹¤ ê³„ì‚° í…ŒìŠ¤íŠ¸
        batch_size = 2
        seq_len = 8
        vocab_size = tokenizer.vocab_size
        
        input_ids = torch.randint(0, vocab_size, (batch_size, seq_len)).to(trainer.device)
        attention_mask = torch.ones(batch_size, seq_len, dtype=torch.bool).to(trainer.device)
        labels = torch.randint(0, vocab_size, (batch_size, seq_len)).to(trainer.device)
        
        with torch.no_grad():
            logits, reasoning_info = model(input_ids, attention_mask, return_reasoning_trace=True)
            loss = trainer.calculate_loss(logits, labels, reasoning_info)
            
            print(f"   âœ… Loss calculation: {loss.item():.4f}")
            print(f"   âœ… Reasoning steps: {reasoning_info['actual_steps']}")
            
            # Orthogonal loss í…ŒìŠ¤íŠ¸
            if hasattr(model, 'lightweight_orthogonal_regularization_loss'):
                orth_loss = model.lightweight_orthogonal_regularization_loss()
                print(f"   âœ… Orthogonal regularization: {orth_loss.item():.4f}")
        
        print("âœ… Training integration tests passed")
        return True
        
    except Exception as e:
        print(f"âŒ Training integration test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ì „ì²´ ê²€ì¦ ì‹¤í–‰"""
    print("ğŸš€ Connection Transformer Unified System Verification")
    print("=" * 70)
    
    results = {}
    
    # 1. í† í¬ë‚˜ì´ì € ì‹œìŠ¤í…œ ê²€ì¦
    results['tokenizer'] = test_tokenizer_system()
    
    # 2. í†µí•© ì„¤ì • ì‹œìŠ¤í…œ ê²€ì¦
    results['configs'] = test_unified_configs()
    
    # 3. ë°ì´í„°ì…‹ ë¡œë”© ê²€ì¦
    results['datasets'] = test_dataset_loading()
    
    # 4. ëª¨ë¸ ì•„í‚¤í…ì²˜ ê²€ì¦
    results['models'] = test_model_architectures()
    
    # 5. í›ˆë ¨ í†µí•© ê²€ì¦
    results['training'] = test_training_integration()
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 70)
    print("ğŸ“‹ Unified System Verification Results")
    print("=" * 70)
    
    for component, success in results.items():
        status = "âœ… í†µê³¼" if success else "âŒ ì‹¤íŒ¨"
        print(f"{component:15}: {status}")
    
    all_passed = all(results.values())
    if all_passed:
        print("\nğŸ‰ í†µí•© ì‹œìŠ¤í…œ ê²€ì¦ ì™„ë£Œ! ëª¨ë“  êµ¬ì„±ìš”ì†Œê°€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.")
        print("\nğŸ“‹ ê¶Œì¥ ì‹¤í—˜ ìˆœì„œ:")
        print("   1. ì‘ì€ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸:")
        print("      python main.py --dataset strategyqa --model connection --model_size nano")
        print("      python main.py --dataset logiqa --model connection --model_size micro")
        print("   2. í° ë°ì´í„°ì…‹ ì‹¤í—˜:")
        print("      python main.py --dataset multinli --model connection --model_size base")
        print("   3. ë² ì´ìŠ¤ë¼ì¸ ë¹„êµ:")
        print("      python main.py --dataset multinli --model baseline --model_size base")
    else:
        print("\nâš ï¸ ì¼ë¶€ ê²€ì¦ ì‹¤íŒ¨. ë¬¸ì œì ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        failed_items = [k for k, v in results.items() if not v]
        print(f"\nì‹¤íŒ¨í•œ í•­ëª©: {', '.join(failed_items)}")
        
        print("\nğŸ”§ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ:")
        if 'tokenizer' in failed_items:
            print("   - pip install transformers>=4.21.0 sentencepiece>=0.1.97")
        if 'datasets' in failed_items:
            print("   - ì¸í„°ë„· ì—°ê²° í™•ì¸ ë° HuggingFace Hub ì ‘ê·¼ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸")
        if 'configs' in failed_items:
            print("   - configs/ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  íŒŒì¼ì´ ì˜¬ë°”ë¥´ê²Œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸")
        if 'models' in failed_items:
            print("   - models/ ë””ë ‰í† ë¦¬ì˜ íŒŒì¼ë“¤ê³¼ PyTorch ë²„ì „ í™•ì¸")
        if 'training' in failed_items:
            print("   - training/ ë””ë ‰í† ë¦¬ì™€ CUDA í™˜ê²½ í™•ì¸")
    
    return all_passed

if __name__ == "__main__":
    main()