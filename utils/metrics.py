# utils/metrics.py
import re
import string
from collections import Counter

def normalize_answer(s):
    """ë‹µë³€ì„ ì •ê·œí™” (ê³µë°±, êµ¬ë‘ì , ëŒ€ì†Œë¬¸ì ì²˜ë¦¬)"""
    def remove_articles(text):
        return re.sub(r'\b(a|an|the)\b', ' ', text)
    
    def white_space_fix(text):
        return ' '.join(text.split())
    
    def remove_punc(text):
        exclude = set(string.punctuation)
        return ''.join(ch for ch in text if ch not in exclude)
    
    def lower(text):
        return text.lower()
    
    return white_space_fix(remove_articles(remove_punc(lower(s))))

def extract_final_answer(text, dataset_type=None):
    """
    âœ… ë°ì´í„°ì…‹ë³„ë¡œ ìµœì í™”ëœ ë‹µë³€ ì¶”ì¶œ
    """
    if not text or text.strip() == "":
        return ""
    
    text = str(text).strip()
    
    # StrategyQA: Yes/No ë‹µë³€ ì¶”ì¶œ
    if dataset_type == "strategyqa" or any(word in text.lower() for word in ["yes", "no"]):
        # Yes/No íŒ¨í„´ ì°¾ê¸° (ëŒ€ì†Œë¬¸ì ë¬´ê´€)
        yes_pattern = re.search(r'\b(yes|true|y)\b', text.lower())
        no_pattern = re.search(r'\b(no|false|n)\b', text.lower())
        
        if yes_pattern and no_pattern:
            # ë‘˜ ë‹¤ ìˆìœ¼ë©´ ë§ˆì§€ë§‰ì— ë‚˜ì˜¨ ê²ƒ ì‚¬ìš©
            yes_pos = yes_pattern.start()
            no_pos = no_pattern.start()
            return "Yes" if yes_pos > no_pos else "No"
        elif yes_pattern:
            return "Yes"
        elif no_pattern:
            return "No"
        
        # íŒ¨í„´ì´ ì—†ìœ¼ë©´ ì²« ê¸€ìë¡œ íŒë‹¨
        first_char = text.lower().strip()[0] if text.strip() else ""
        if first_char == 'y':
            return "Yes"
        elif first_char == 'n':
            return "No"
    
    # GSM8K: ìˆ«ì ë‹µë³€ ì¶”ì¶œ
    if dataset_type == "gsm8k" or re.search(r'\d', text):
        # "#### 24" í˜•ì‹ ë¨¼ì € í™•ì¸
        gsm_pattern = re.search(r'####\s*([+-]?\d+(?:\.\d+)?)', text)
        if gsm_pattern:
            return gsm_pattern.group(1).strip()
        
        # ì¼ë°˜ ìˆ«ì íŒ¨í„´ (ë‹¨ìœ„ ì œê±°)
        # $24, 24 dollars, 24.5, -5 ë“± ì²˜ë¦¬
        number_patterns = [
            r'([+-]?\d+(?:\.\d+)?)\s*(?:dollars?|usd|\$)?(?:\s|$)',  # 24 dollars, 24$
            r'\$?\s*([+-]?\d+(?:\.\d+)?)',  # $24, 24
            r'([+-]?\d+(?:\.\d+)?)'  # ë‹¨ìˆœ ìˆ«ì
        ]
        
        for pattern in number_patterns:
            numbers = re.findall(pattern, text, re.IGNORECASE)
            if numbers:
                # ë§ˆì§€ë§‰ ìˆ«ì ì‚¬ìš© (ë³´í†µ ìµœì¢… ë‹µ)
                return numbers[-1].strip()
    
    # LogiQA: A, B, C, D ì„ íƒì§€ ì¶”ì¶œ
    if dataset_type == "logiqa" or re.search(r'\b[ABCD]\b', text.upper()):
        choices = re.findall(r'\b([ABCD])\b', text.upper())
        if choices:
            return choices[-1]  # ë§ˆì§€ë§‰ ì„ íƒì§€ ì‚¬ìš©
        
        # ê´„í˜¸ ì•ˆì˜ ì„ íƒì§€ë„ í™•ì¸: (A), (B) ë“±
        paren_choices = re.findall(r'\(([ABCD])\)', text.upper())
        if paren_choices:
            return paren_choices[-1]
    
    # MultiNLI: entailment, neutral, contradiction
    if dataset_type == "multinli" or any(word in text.lower() for word in ["entailment", "neutral", "contradiction"]):
        text_lower = text.lower()
        
        # ì™„ì „í•œ ë‹¨ì–´ë¡œ ë§¤ì¹­
        if re.search(r'\bentailment\b', text_lower):
            return "entailment"
        elif re.search(r'\bneutral\b', text_lower):
            return "neutral"
        elif re.search(r'\bcontradiction\b', text_lower):
            return "contradiction"
        
        # ì¶•ì•½í˜•ë„ í™•ì¸
        if re.search(r'\bentail\b', text_lower):
            return "entailment"
        elif re.search(r'\bcontradict\b', text_lower):
            return "contradiction"
    
    # ê¸°ë³¸ê°’: ì²« ë²ˆì§¸ ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ ë°˜í™˜
    words = text.strip().split()
    return words[0] if words else text

def exact_match_score(prediction, ground_truth, dataset_type=None):
    """âœ… ë°ì´í„°ì…‹ë³„ ì •í™•í•œ ì¼ì¹˜ ì ìˆ˜"""
    # ë‹µë³€ ì¶”ì¶œ
    pred_answer = extract_final_answer(prediction, dataset_type)
    true_answer = extract_final_answer(ground_truth, dataset_type)
    
    # ì •ê·œí™” í›„ ë¹„êµ
    pred_norm = normalize_answer(pred_answer)
    true_norm = normalize_answer(true_answer)
    
    # íŠ¹ë³„ ì¼€ì´ìŠ¤ ì²˜ë¦¬
    if dataset_type == "gsm8k":
        # ìˆ«ìëŠ” float ë³€í™˜ í›„ ë¹„êµ
        try:
            pred_num = float(pred_norm) if pred_norm else None
            true_num = float(true_norm) if true_norm else None
            if pred_num is not None and true_num is not None:
                return abs(pred_num - true_num) < 1e-6  # ë¶€ë™ì†Œìˆ˜ì  ì˜¤ì°¨ ê³ ë ¤
        except:
            pass
    
    return pred_norm == true_norm

def calculate_accuracy(predictions, targets, dataset_type=None):
    """âœ… ë°ì´í„°ì…‹ë³„ ìµœì í™”ëœ ì •í™•ë„ ê³„ì‚°"""
    if len(predictions) != len(targets):
        raise ValueError(f"Predictions and targets must have same length: {len(predictions)} vs {len(targets)}")
    
    if len(predictions) == 0:
        return 0.0
    
    # ë°ì´í„°ì…‹ íƒ€ì… ìë™ ê°ì§€ (ì§€ì •ë˜ì§€ ì•Šì€ ê²½ìš°)
    if dataset_type is None:
        dataset_type = detect_dataset_type(targets)
    
    correct = 0
    total = len(predictions)
    
    # ë””ë²„ê¹…ì„ ìœ„í•œ ìƒ˜í”Œ ì¶œë ¥
    debug_samples = min(5, total)
    print(f"\nğŸ” Accuracy Debug (dataset_type: {dataset_type}):")
    
    for i, (pred, target) in enumerate(zip(predictions, targets)):
        # ë‹µë³€ ì¶”ì¶œ
        extracted_pred = extract_final_answer(str(pred), dataset_type)
        extracted_target = extract_final_answer(str(target), dataset_type)
        
        # ì •í™•í•œ ì¼ì¹˜ í™•ì¸
        is_correct = exact_match_score(str(pred), str(target), dataset_type)
        if is_correct:
            correct += 1
        
        # ë””ë²„ê¹… ì¶œë ¥ (ì²˜ìŒ ëª‡ ê°œë§Œ)
        if i < debug_samples:
            status = "âœ…" if is_correct else "âŒ"
            print(f"  {status} Pred: '{pred}' -> '{extracted_pred}' | Target: '{target}' -> '{extracted_target}'")
    
    accuracy = correct / total
    print(f"ğŸ¯ Final accuracy: {correct}/{total} = {accuracy:.4f}")
    
    return accuracy

def detect_dataset_type(targets):
    """íƒ€ê²Ÿ ë°ì´í„°ë¡œë¶€í„° ë°ì´í„°ì…‹ íƒ€ì… ìë™ ê°ì§€"""
    if not targets:
        return None
    
    # ìƒ˜í”Œë§í•´ì„œ í™•ì¸
    sample_targets = targets[:min(10, len(targets))]
    
    yes_no_count = 0
    number_count = 0
    choice_count = 0
    entail_count = 0
    
    for target in sample_targets:
        target_str = str(target).lower().strip()
        
        # Yes/No íŒ¨í„´
        if target_str in ['yes', 'no', 'true', 'false']:
            yes_no_count += 1
        
        # ìˆ«ì íŒ¨í„´
        if re.search(r'^\d+(\.\d+)?$', target_str):
            number_count += 1
        
        # ì„ íƒì§€ íŒ¨í„´
        if re.search(r'^[abcd]$', target_str):
            choice_count += 1
        
        # Entailment íŒ¨í„´
        if target_str in ['entailment', 'neutral', 'contradiction']:
            entail_count += 1
    
    # ê°€ì¥ ë§ì€ íŒ¨í„´ìœ¼ë¡œ ê²°ì •
    counts = {
        'strategyqa': yes_no_count,
        'gsm8k': number_count,
        'logiqa': choice_count,
        'multinli': entail_count
    }
    
    detected_type = max(counts, key=counts.get)
    max_count = counts[detected_type]
    
    # í™•ì‹ ë„ê°€ ë‚®ìœ¼ë©´ None ë°˜í™˜
    if max_count < len(sample_targets) * 0.3:
        return None
    
    return detected_type

def f1_score(prediction, ground_truth, dataset_type=None):
    """F1 ì ìˆ˜ (í† í° ë ˆë²¨)"""
    pred_answer = extract_final_answer(prediction, dataset_type)
    true_answer = extract_final_answer(ground_truth, dataset_type)
    
    prediction_tokens = normalize_answer(pred_answer).split()
    ground_truth_tokens = normalize_answer(true_answer).split()
    
    if len(prediction_tokens) == 0 or len(ground_truth_tokens) == 0:
        return int(prediction_tokens == ground_truth_tokens)
    
    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)
    num_same = sum(common.values())
    
    if num_same == 0:
        return 0
    
    precision = 1.0 * num_same / len(prediction_tokens)
    recall = 1.0 * num_same / len(ground_truth_tokens)
    f1 = (2 * precision * recall) / (precision + recall)
    
    return f1

def calculate_detailed_metrics(predictions, targets, dataset_type=None):
    """ìƒì„¸ ë©”íŠ¸ë¦­ ê³„ì‚°"""
    if len(predictions) != len(targets):
        raise ValueError(f"Predictions and targets must have same length")
    
    if dataset_type is None:
        dataset_type = detect_dataset_type(targets)
    
    exact_matches = []
    f1_scores = []
    
    for pred, target in zip(predictions, targets):
        em = exact_match_score(pred, target, dataset_type)
        f1 = f1_score(pred, target, dataset_type)
        
        exact_matches.append(em)
        f1_scores.append(f1)
    
    return {
        'exact_match': sum(exact_matches) / len(exact_matches),
        'f1': sum(f1_scores) / len(f1_scores),
        'total_samples': len(predictions),
        'detected_dataset_type': dataset_type
    }

def analyze_error_cases(predictions, targets, dataset_type=None, max_examples=10):
    """ì˜¤ë¥˜ ì‚¬ë¡€ ë¶„ì„"""
    if dataset_type is None:
        dataset_type = detect_dataset_type(targets)
    
    errors = []
    
    for i, (pred, target) in enumerate(zip(predictions, targets)):
        extracted_pred = extract_final_answer(str(pred), dataset_type)
        extracted_target = extract_final_answer(str(target), dataset_type)
        
        if not exact_match_score(pred, target, dataset_type):
            errors.append({
                'index': i,
                'prediction': pred,
                'target': target,
                'extracted_prediction': extracted_pred,
                'extracted_target': extracted_target,
                'f1_score': f1_score(pred, target, dataset_type),
                'dataset_type': dataset_type
            })
    
    # F1 ì ìˆ˜ê°€ ë‚®ì€ ìˆœìœ¼ë¡œ ì •ë ¬
    errors.sort(key=lambda x: x['f1_score'])
    
    return errors[:max_examples]