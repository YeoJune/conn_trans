# utils/metrics.py
import re
import string
from typing import List, Optional, Tuple
import logging

def normalize_answer(s: str) -> str:
    """ë‹µë³€ ì •ê·œí™” - ë” ê²¬ê³ í•˜ê²Œ"""
    if not s:
        return ""
    
    s = str(s).lower().strip()
    # ê´€ì‚¬ ì œê±°
    s = re.sub(r'\b(a|an|the)\b', ' ', s)
    # íŠ¹ìˆ˜ë¬¸ì ì œê±° (ì•ŒíŒŒë²³, ìˆ«ì, ê³µë°±ë§Œ ìœ ì§€)
    s = re.sub(r'[^\w\s]', '', s)
    # ì—°ì† ê³µë°± ì •ë¦¬
    return ' '.join(s.split())

def extract_final_answer(text: str, dataset_type: Optional[str] = None) -> str:
    """T5 ë‹µë³€ì—ì„œ ìµœì¢… ë‹µ ì¶”ì¶œ - ë” ì •í™•í•˜ê²Œ"""
    if not text:
        return ""
    
    text = str(text).strip()
    if not text:
        return ""
    
    # ì²« ë²ˆì§¸ ë‹¨ì–´ ì¶”ì¶œ
    words = text.split()
    first_word = words[0] if words else ""
    
    if dataset_type == "strategyqa":
        # Yes/No ì§ˆë¬¸ ì²˜ë¦¬
        first_lower = first_word.lower()
        
        # ëª…í™•í•œ Yes íŒ¨í„´
        if any(pattern in first_lower for pattern in ['yes', 'true', 'correct', 'right']):
            return "Yes"
        # ëª…í™•í•œ No íŒ¨í„´  
        elif any(pattern in first_lower for pattern in ['no', 'false', 'incorrect', 'wrong']):
            return "No"
        # ìˆ«ìë¡œ í‘œí˜„ëœ ê²½ìš°
        elif first_lower in ['1', 'one']:
            return "Yes"
        elif first_lower in ['0', 'zero']:
            return "No"
        
        # ê¸°ë³¸ê°’: ì²« ê¸€ì ê¸°ì¤€
        return "Yes" if first_lower.startswith('y') else "No"
    
    elif dataset_type == "gsm8k":
        # ìˆ˜í•™ ë¬¸ì œ - ìˆ«ì ì¶”ì¶œ
        # ì²« ë²ˆì§¸ ë‹¨ì–´ê°€ ìˆ«ìì¸ì§€ í™•ì¸
        first_numbers = re.findall(r'^-?\d+(?:\.\d+)?$', first_word)
        if first_numbers:
            try:
                # ì •ìˆ˜ë¡œ ë³€í™˜ ê°€ëŠ¥í•˜ë©´ ì •ìˆ˜ë¡œ, ì•„ë‹ˆë©´ ì‹¤ìˆ˜ë¡œ
                num = float(first_numbers[0])
                if num.is_integer():
                    return str(int(num))
                else:
                    return str(num)
            except ValueError:
                pass
        
        # ì²« ë²ˆì§¸ ë‹¨ì–´ê°€ ìˆ«ìê°€ ì•„ë‹ˆë©´ "error" ë°˜í™˜ (í‹€ë¦° ê²ƒìœ¼ë¡œ ê°„ì£¼)
        return "error"
    
    elif dataset_type == "logiqa":
        # ë‹¤ì¤‘ ì„ íƒ ë¬¸ì œ - A, B, C, D
        first_upper = first_word.upper()
        
        # ì§ì ‘ì ì¸ ì„ íƒì§€
        if first_upper in ['A', 'B', 'C', 'D']:
            return first_upper
        
        # ê´„í˜¸ë‚˜ ê¸°íƒ€ ë¬¸ì ì œê±° í›„ í™•ì¸
        clean = re.sub(r'[^\w]', '', first_upper)
        if clean in ['A', 'B', 'C', 'D']:
            return clean
        
        # ë‹¨ì–´ë¡œ ëœ ì„ íƒì§€ ì²˜ë¦¬
        choice_map = {
            'FIRST': 'A', 'ONE': 'A', '1': 'A',
            'SECOND': 'B', 'TWO': 'B', '2': 'B', 
            'THIRD': 'C', 'THREE': 'C', '3': 'C',
            'FOURTH': 'D', 'FOUR': 'D', '4': 'D'
        }
        return choice_map.get(first_upper, "A")  # ê¸°ë³¸ê°’ A
    
    elif dataset_type == "multinli":
        # ìì—°ì–´ ì¶”ë¡  - entailment, neutral, contradiction
        first_lower = first_word.lower()
        
        # ëª…í™•í•œ ë§¤ì¹­
        if first_lower.startswith('ent'):
            return "entailment"
        elif first_lower.startswith('neu'):
            return "neutral"  
        elif first_lower.startswith('con'):
            return "contradiction"
        
        # ë™ì˜ì–´ ì²˜ë¦¬
        entailment_words = ['yes', 'true', 'follows', 'implies', 'supports']
        neutral_words = ['maybe', 'unclear', 'unknown', 'possible']
        contradiction_words = ['no', 'false', 'contradicts', 'opposes']
        
        if any(word in first_lower for word in entailment_words):
            return "entailment"
        elif any(word in first_lower for word in neutral_words):
            return "neutral"
        elif any(word in first_lower for word in contradiction_words):
            return "contradiction"
        
        return "neutral"  # ê¸°ë³¸ê°’
    
    # ì•Œ ìˆ˜ ì—†ëŠ” ë°ì´í„°ì…‹ íƒ€ì…ì¸ ê²½ìš° ì²« ë‹¨ì–´ ë°˜í™˜
    return first_word

def exact_match_score(prediction: str, ground_truth: str, dataset_type: Optional[str] = None) -> bool:
    """ì •í™•í•œ ì¼ì¹˜ ì—¬ë¶€ - ë” ì—„ê²©í•˜ê²Œ"""
    try:
        pred = extract_final_answer(prediction, dataset_type)
        true = extract_final_answer(ground_truth, dataset_type)
        
        pred_norm = normalize_answer(pred)
        true_norm = normalize_answer(true)
        
        # ìˆ˜í•™ ë¬¸ì œëŠ” ìˆ«ì ë¹„êµ
        if dataset_type == "gsm8k":
            try:
                pred_num = float(pred_norm) if pred_norm else 0.0
                true_num = float(true_norm) if true_norm else 0.0
                return abs(pred_num - true_num) < 1e-6  # ë¶€ë™ì†Œìˆ˜ì  ì˜¤ì°¨ ê³ ë ¤
            except ValueError:
                # ìˆ«ì ë³€í™˜ ì‹¤íŒ¨ ì‹œ ë¬¸ìì—´ ë¹„êµ
                pass
        
        # ê¸°ë³¸ì ìœ¼ë¡œ ì •ê·œí™”ëœ ë¬¸ìì—´ ë¹„êµ
        return pred_norm == true_norm
        
    except Exception as e:
        # ì˜ˆì™¸ ë°œìƒ ì‹œ False ë°˜í™˜ (ë¡œê¹…ì€ ì„ íƒì )
        logging.debug(f"Exact match error: {e}")
        return False

def calculate_accuracy(predictions: List[str], targets: List[str], 
                      dataset_type: Optional[str] = None, 
                      verbose: bool = True) -> float:
    """ì •í™•ë„ ê³„ì‚° - ë¡œê¹… ê°œì„ """
    if not predictions or not targets:
        return 0.0
    
    if len(predictions) != len(targets):
        if verbose:
            print(f"âš ï¸ Length mismatch: predictions={len(predictions)}, targets={len(targets)}")
        # ê¸¸ì´ê°€ ë‹¤ë¥´ë©´ ì§§ì€ ìª½ì— ë§ì¶¤
        min_len = min(len(predictions), len(targets))
        predictions = predictions[:min_len]
        targets = targets[:min_len]
    
    # ë°ì´í„°ì…‹ íƒ€ì… ìë™ ê°ì§€
    if dataset_type is None:
        dataset_type = detect_dataset_type(targets)
        if verbose and dataset_type:
            print(f"ğŸ” Dataset type auto-detected: {dataset_type}")
    
    # ì •í™•ë„ ê³„ì‚°
    correct_count = 0
    total_count = len(predictions)
    
    for i, (pred, target) in enumerate(zip(predictions, targets)):
        if exact_match_score(pred, target, dataset_type):
            correct_count += 1
    
    accuracy = correct_count / total_count if total_count > 0 else 0.0
    
    if verbose:
        print(f"ğŸ¯ Accuracy: {correct_count}/{total_count} = {accuracy:.4f} (type: {dataset_type or 'unknown'})")
    
    return accuracy

def detect_dataset_type(targets: List[str]) -> Optional[str]:
    """íƒ€ê²Ÿìœ¼ë¡œë¶€í„° ë°ì´í„°ì…‹ íƒ€ì… ìë™ ê°ì§€ - ë” ì •í™•í•˜ê²Œ"""
    if not targets:
        return None
    
    # ìƒ˜í”Œ í¬ê¸° ì¡°ì • (ìµœëŒ€ 20ê°œ, ìµœì†Œ 5ê°œ)
    sample_size = min(max(len(targets) // 10, 5), 20)
    sample = targets[:sample_size]
    
    # ê° íƒ€ì…ë³„ íŒ¨í„´ ì¹´ìš´íŠ¸
    counters = {
        'strategyqa': 0,
        'gsm8k': 0, 
        'logiqa': 0,
        'multinli': 0
    }
    
    for target in sample:
        target_str = str(target).lower().strip()
        
        # StrategyQA: Yes/No ë‹µë³€
        if target_str in ['yes', 'no', 'true', 'false', '1', '0']:
            counters['strategyqa'] += 1
        
        # GSM8K: ìˆ«ì ë‹µë³€
        elif re.match(r'^-?\d+(\.\d+)?$', target_str):
            counters['gsm8k'] += 1
            
        # LogiQA: A, B, C, D ì„ íƒì§€
        elif target_str.upper() in ['A', 'B', 'C', 'D']:
            counters['logiqa'] += 1
            
        # MultiNLI: entailment, neutral, contradiction
        elif target_str in ['entailment', 'neutral', 'contradiction']:
            counters['multinli'] += 1
    
    # ê°€ì¥ ë§ì´ ë§¤ì¹­ëœ íƒ€ì… ë°˜í™˜ (50% ì´ìƒ ë§¤ì¹­ ì‹œ)
    threshold = sample_size * 0.5
    
    for dataset_type, count in counters.items():
        if count >= threshold:
            return dataset_type
    
    return None

def get_accuracy_breakdown(predictions: List[str], targets: List[str], 
                          dataset_type: Optional[str] = None) -> dict:
    """ì •í™•ë„ ì„¸ë¶€ ë¶„ì„ ì •ë³´ ë°˜í™˜"""
    if not predictions or not targets:
        return {'accuracy': 0.0, 'correct': 0, 'total': 0, 'details': []}
    
    # ê¸¸ì´ ë§ì¶¤
    min_len = min(len(predictions), len(targets))
    predictions = predictions[:min_len]
    targets = targets[:min_len]
    
    # ë°ì´í„°ì…‹ íƒ€ì… ê°ì§€
    if dataset_type is None:
        dataset_type = detect_dataset_type(targets)
    
    # ì„¸ë¶€ ë¶„ì„
    details = []
    correct_count = 0
    
    for i, (pred, target) in enumerate(zip(predictions, targets)):
        is_correct = exact_match_score(pred, target, dataset_type)
        if is_correct:
            correct_count += 1
            
        details.append({
            'index': i,
            'prediction': pred,
            'target': target,
            'correct': is_correct,
            'extracted_pred': extract_final_answer(pred, dataset_type),
            'extracted_target': extract_final_answer(target, dataset_type)
        })
    
    return {
        'accuracy': correct_count / len(predictions),
        'correct': correct_count,
        'total': len(predictions),
        'dataset_type': dataset_type,
        'details': details
    }