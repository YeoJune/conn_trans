# dataset/multinli_dataset.py
from datasets import load_dataset
from .base_dataset import BaseReasoningDataset

class MultiNLIDataset(BaseReasoningDataset):
    
    # ğŸ”§ FIX: ì˜¬ë°”ë¥¸ ë¼ë²¨ ë§¤í•‘ (MultiNLI ê³µì‹ ë¬¸ì„œ ê¸°ì¤€)
    LABEL_MAP = {0: "entailment", 1: "neutral", 2: "contradiction"}
    REVERSE_LABEL_MAP = {"entailment": 0, "neutral": 1, "contradiction": 2}
    
    @property
    def dataset_name(self):
        return "MultiNLI"
    
    def _load_raw_data(self):
        # ğŸ”§ FIX: ë‹¤ì–‘í•œ ì†ŒìŠ¤ì™€ ì˜¬ë°”ë¥¸ split ì´ë¦„ ì‹œë„
        sources = [
            ("nyu-mll/multi_nli", None),
            ("multi_nli", None),
            ("multinli", None)
        ]
        
        for source_name, config in sources:
            try:
                # ğŸ”§ FIX: ì˜¬ë°”ë¥¸ split ë§¤í•‘
                split_mapping = {
                    "train": "train",
                    "validation": "validation_matched", 
                    "test": "validation_mismatched",  # test setì´ ì—†ìœ¼ë¯€ë¡œ mismatchedë¥¼ testë¡œ ì‚¬ìš©
                    "dev": "validation_matched",
                    "eval": "validation_matched"
                }
                
                actual_split = split_mapping.get(self.split, self.split)
                
                if config:
                    dataset = load_dataset(source_name, config, split=actual_split)
                else:
                    dataset = load_dataset(source_name, split=actual_split)
                
                print(f"âœ… Loaded {source_name} {actual_split}: {len(dataset)} examples")
                return dataset
                
            except Exception as e:
                print(f"âŒ Failed to load {source_name}: {str(e)[:100]}...")
                continue
        
        raise RuntimeError("Failed to load MultiNLI from any source")
    
    def _process_item(self, item, idx):
        # ğŸ”§ FIX: í•„ë“œëª… ì •ê·œí™” ë° ë¼ë²¨ ê²€ì¦
        premise = item.get('premise', '').strip()
        hypothesis = item.get('hypothesis', '').strip()
        label = item.get('label', -1)
        
        # ğŸš¨ ì¤‘ìš”: ì˜ëª»ëœ ë¼ë²¨ (-1) í•„í„°ë§
        if label == -1:
            print(f"âš ï¸ MultiNLI item {idx}: invalid label (-1), skipping")
            return None
        
        # ğŸ”§ FIX: ë¼ë²¨ ê²€ì¦ ë° ë³€í™˜
        if label not in self.LABEL_MAP:
            print(f"âš ï¸ MultiNLI item {idx}: unknown label {label}, using neutral")
            label = 1  # neutral as default
        
        target_text = self.LABEL_MAP[label]
        
        # ğŸ”§ FIX: ì…ë ¥ í…ìŠ¤íŠ¸ í˜•ì‹ ê°œì„ 
        input_text = (f"{self.task_prefix}: "
                     f"Premise: {premise} "
                     f"Hypothesis: {hypothesis}")
        
        return {
            'input_text': input_text,
            'target_text': target_text,
            'metadata': {
                'premise': premise,
                'hypothesis': hypothesis,
                'genre': item.get('genre', 'unknown'),
                'original_label': label,
                'pair_id': item.get('pairID', f'pair_{idx}'),
                'index': idx
            }
        }
    
    def _is_valid_item(self, item):
        """MultiNLI íŠ¹í™” ê²€ì¦ - ë” ì—„ê²©í•œ í•„í„°ë§"""
        base_valid = super()._is_valid_item(item)
        if not base_valid:
            return False
        
        # ê¸¸ì´ ì œí•œ (ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ì´ë¯€ë¡œ)
        if len(item['input_text']) > 800:
            return False
        
        # ë©”íƒ€ë°ì´í„° ê²€ì¦
        metadata = item.get('metadata', {})
        premise = metadata.get('premise', '')
        hypothesis = metadata.get('hypothesis', '')
        
        # premiseì™€ hypothesisê°€ ëª¨ë‘ ìˆì–´ì•¼ í•¨
        if not premise or not hypothesis:
            return False
        
        # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ ì œì™¸
        if len(premise.split()) < 3 or len(hypothesis.split()) < 3:
            return False
            
        return True
    
    def _get_default_answer(self):
        return "neutral"
    
    def verify_split_integrity(self):
        """ë°ì´í„° ë¶„í•  ë¬´ê²°ì„± ê²€ì¦"""
        print(f"\nğŸ” MultiNLI {self.split} Split Verification")
        print(f"ğŸ“Š Total samples: {len(self.data)}")
        
        # ë¼ë²¨ ë¶„í¬ ë° ì¥ë¥´ ë¶„í¬ í™•ì¸
        label_dist = {}
        genre_dist = {}
        invalid_labels = 0
        
        sample_size = min(1000, len(self.data))  # í° ë°ì´í„°ì…‹ì´ë¯€ë¡œ ìƒ˜í”Œë§
        
        for i in range(sample_size):
            try:
                item = self.__getitem__(i)
                target = item['target_text']
                metadata = item.get('metadata', {})
                
                # ë¼ë²¨ ë¶„í¬
                label_dist[target] = label_dist.get(target, 0) + 1
                
                # ì¥ë¥´ ë¶„í¬
                genre = metadata.get('genre', 'unknown')
                genre_dist[genre] = genre_dist.get(genre, 0) + 1
                
                # ì›ë³¸ ë¼ë²¨ ê²€ì¦
                original_label = metadata.get('original_label', -1)
                if original_label == -1:
                    invalid_labels += 1
                
            except Exception as e:
                print(f"âŒ Error in item {i}: {e}")
        
        print(f"ğŸ¯ Label distribution (sample of {sample_size}):")
        for label, count in sorted(label_dist.items()):
            percentage = (count / sample_size) * 100
            print(f"   {label}: {count} ({percentage:.1f}%)")
        
        print(f"ğŸ“š Genre distribution (top 5):")
        sorted_genres = sorted(genre_dist.items(), key=lambda x: x[1], reverse=True)
        for genre, count in sorted_genres[:5]:
            percentage = (count / sample_size) * 100
            print(f"   {genre}: {count} ({percentage:.1f}%)")
        
        if invalid_labels > 0:
            print(f"âš ï¸ WARNING: Found {invalid_labels} items with invalid labels (-1)")
        
        # ê²€ì¦
        if len(label_dist) != 3:
            print(f"ğŸš¨ WARNING: Expected 3 labels, found {len(label_dist)}")
        elif all(label in ["entailment", "neutral", "contradiction"] for label in label_dist.keys()):
            print("âœ… All labels are valid NLI categories.")
        else:
            print("ğŸš¨ WARNING: Found unexpected label categories!")
        
        # ê· í˜•ì„± ê²€ì‚¬ (NLIëŠ” ë³´í†µ ë¹„êµì  ê· í˜•ì¡íŒ ë¶„í¬)
        if label_dist:
            max_ratio = max(label_dist.values()) / sum(label_dist.values())
            if max_ratio > 0.6:  # 60% ì´ìƒì´ë©´ ë¶ˆê· í˜•
                print(f"âš ï¸ WARNING: Label distribution is imbalanced (max: {max_ratio:.1%})")
            else:
                print("âœ… Label distribution is reasonably balanced.")
        
        # ìƒ˜í”Œ ì¶œë ¥
        print(f"\nğŸ“‹ Sample examples:")
        for i in range(min(3, len(self.data))):
            item = self.__getitem__(i)
            metadata = item.get('metadata', {})
            premise = metadata.get('premise', '')[:50]
            hypothesis = metadata.get('hypothesis', '')[:50]
            target = item['target_text']
            
            print(f"  {i+1}. {target} | P: '{premise}...' H: '{hypothesis}...'")
        
        return {
            'label_distribution': label_dist,
            'genre_distribution': genre_dist,
            'invalid_labels': invalid_labels,
            'sample_size': sample_size
        }