# dataset/strategyqa_dataset.py
from datasets import load_dataset
from .base_dataset import BaseReasoningDataset
import torch

class StrategyQADataset(BaseReasoningDataset):
    @property
    def dataset_name(self):
        return "StrategyQA"
    
    def _load_raw_data(self):
        """StrategyQA ë°ì´í„° ë¡œë”©"""
        sources = [
            "ChilleD/StrategyQA",
            "wics/strategy-qa"
        ]
        
        for source in sources:
            try:
                dataset = load_dataset(source, split=self.split)
                print(f"âœ… Loaded {source} {self.split}: {len(dataset)} examples")
                return dataset
            except Exception as e:
                print(f"âŒ {source} failed: {str(e)[:50]}...")
                continue
        
        raise RuntimeError("Failed to load StrategyQA")
    
    def _process_item(self, item, idx):
        """ì›ë³¸ ë°ì´í„° í•­ëª©ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì „ì²˜ë¦¬ ì—†ìŒ)"""
        # ê¸°ë³¸ ê²€ì¦ë§Œ ìˆ˜í–‰
        question = item.get('question', '').strip()
        answer = item.get('answer', '')
        
        if not question:
            return None
            
        return item  # âœ… ì›ë³¸ ë°ì´í„° ê·¸ëŒ€ë¡œ ë°˜í™˜
    
    def _tokenize_item(self, item):
        """StrategyQA ì „ìš© í† í¬ë‚˜ì´ì§• - BaseDataset ì˜¤ë²„ë¼ì´ë“œ"""
        
        # 1. ì§ˆë¬¸ê³¼ ë‹µë³€ ì¶”ì¶œ
        question = item.get('question', '').strip()
        answer = item.get('answer', '')
        
        # 2. ë‹µë³€ ì •ê·œí™”
        if isinstance(answer, str):
            if answer.lower() in ['yes', 'true']:
                target_text = "Yes"
            elif answer.lower() in ['no', 'false']:
                target_text = "No"
            else:
                target_text = "No"  # ê¸°ë³¸ê°’
        elif isinstance(answer, bool):
            target_text = "Yes" if answer else "No"
        else:
            target_text = "No"
        
        # 3. ì…ë ¥ í…ìŠ¤íŠ¸ êµ¬ì„±
        input_text = f"{self.task_prefix}: {question}"
        
        # 4. í† í¬ë‚˜ì´ì§•
        src_inputs = self.tokenizer(
            input_text,
            max_length=self.max_length,
            padding=False,
            truncation=True,
            return_tensors='pt'
        )
        
        tgt_inputs = self.tokenizer(
            target_text,
            max_length=self.answer_max_length,
            padding=False,
            truncation=True,
            return_tensors='pt'
        )
        
        # 5. T5 ë°©ì‹ decoder_input_ids
        decoder_input_ids = self._create_decoder_input_ids(tgt_inputs.input_ids.squeeze())
        
        # 6. Labels
        labels = tgt_inputs.input_ids.squeeze().clone()
        
        return {
            'input_ids': src_inputs.input_ids.squeeze(),
            'attention_mask': src_inputs.attention_mask.squeeze(),
            'decoder_input_ids': decoder_input_ids,
            'decoder_attention_mask': tgt_inputs.attention_mask.squeeze(),
            'labels': labels,
            'target_text': target_text,
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            'question': question,
            'original_answer': answer,
            'decomposition': item.get('decomposition', []),
            'evidence': item.get('evidence', [])
        }
    
    def _create_decoder_input_ids(self, target_ids):
        """T5 ë°©ì‹ decoder input ìƒì„±"""
        if len(target_ids.shape) == 0:
            target_ids = target_ids.unsqueeze(0)
            
        start_token = getattr(self.tokenizer, 'decoder_start_token_id', self.tokenizer.pad_token_id)
        
        decoder_input_ids = torch.cat([
            torch.tensor([start_token]), 
            target_ids[:-1]
        ])
        return decoder_input_ids
    
    def _is_valid_item(self, item):
        """StrategyQA ê²€ì¦"""
        question = item.get('question', '').strip()
        answer = item.get('answer', '')
        
        return (
            len(question) > 0 and
            len(question.split()) >= 3 and  # ìµœì†Œ 3ë‹¨ì–´
            answer is not None
        )
    
    def _get_default_answer(self):
        return "No"
    
    def verify_split_integrity(self):
        """ë°ì´í„° ê²€ì¦"""
        print(f"\nğŸ” StrategyQA {self.split} Split Verification")
        print(f"ğŸ“Š Total samples: {len(self.data)}")
        
        # ìƒ˜í”Œ í™•ì¸
        answers = []
        for i in range(min(10, len(self.data))):
            try:
                item = self.__getitem__(i)
                answers.append(item['target_text'])
                
                if i < 3:  # ì²« 3ê°œ ìƒ˜í”Œ ì¶œë ¥
                    print(f"\nSample {i+1}:")
                    print(f"  Question: {item.get('question', 'N/A')}")
                    print(f"  Target: {item['target_text']}")
                    print(f"  Input shape: {item['input_ids'].shape}")
                    print(f"  Decoder shape: {item['decoder_input_ids'].shape}")
                    
            except Exception as e:
                print(f"âŒ Error in item {i}: {e}")
                import traceback
                traceback.print_exc()
        
        from collections import Counter
        answer_dist = Counter(answers)
        print(f"\nğŸ¯ Answer distribution: {answer_dist}")
        
        return answer_dist