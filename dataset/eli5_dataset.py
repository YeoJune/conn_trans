# dataset/eli5_dataset.py
from datasets import load_dataset
from .base_dataset import BaseReasoningDataset

class ELI5Dataset(BaseReasoningDataset):
    """ELI5 - Explain Like I'm 5 dataset for multi-step reasoning and explanation"""
    
    @property
    def dataset_name(self):
        return "ELI5"
    
    def _load_raw_data(self):
        """Load ELI5 dataset from HuggingFace"""
        try:
            # ğŸ”§ FIX: ë” ì•ˆì •ì ì¸ ë°ì´í„°ì…‹ ë¡œë”©
            if self.split == "train":
                dataset = load_dataset("eli5_category", split="train[:20000]")  # ì ë‹¹í•œ í¬ê¸°
            elif self.split in ["test", "validation"]:
                dataset = load_dataset("eli5_category", split="validation1[:2000]")  
            else:
                dataset = load_dataset("eli5_category", split="train[:5000]")  
            
            print(f"âœ… Loaded ELI5 {self.split}: {len(dataset)} examples")
            return dataset
            
        except Exception as e:
            print(f"âŒ Failed to load ELI5: {e}")
            # ğŸ”§ ë” ê°„ë‹¨í•œ fallback 
            try:
                dataset = load_dataset("eli5", split="train_asks[:1000]")
                print(f"âš ï¸ Using ELI5 fallback: {len(dataset)} examples")
                return dataset
            except:
                raise RuntimeError("Failed to load ELI5 from any source")
    
    def _process_item(self, item, idx):
        """Process ELI5 item - íŒŒì´í”„ë¼ì¸ í˜¸í™˜ì„± ê°œì„ """
        # ğŸ”§ FIX: í•„ë“œëª… ì•ˆì „ ì²˜ë¦¬
        title = item.get('title', item.get('question', '')).strip()
        selftext = item.get('selftext', item.get('body', '')).strip()
        
        # ğŸ”§ FIX: answers êµ¬ì¡° ì•ˆì „ ì²˜ë¦¬
        answers_data = item.get('answers', {})
        if isinstance(answers_data, dict):
            answers = answers_data.get('text', [])
        elif isinstance(answers_data, list):
            answers = answers_data
        else:
            answers = []
        
        # ì§ˆë¬¸ êµ¬ì„± - ë” ê°„ê²°í•˜ê²Œ
        if selftext and len(selftext) > 20:
            # selftextê°€ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
            if len(selftext) > 200:
                selftext = selftext[:200] + "..."
            question = f"{title} {selftext}"
        else:
            question = title
        
        # ğŸ”§ FIX: ë‹µë³€ ì„ íƒ ë¡œì§ ê°œì„ 
        target_answer = self._select_best_answer(answers)
        
        # ğŸ”§ FIX: ì…ë ¥ í”„ë¡¬í”„íŠ¸ ê°œì„  (T5 ìŠ¤íƒ€ì¼)
        input_text = f"{self.task_prefix}: {question.strip()}"
        
        return {
            'input_text': input_text,
            'target_text': target_answer,
            'metadata': {
                'question': title,
                'context': selftext,
                'original_length': len(target_answer),
                'index': idx,
                'num_answers': len(answers)  # ë””ë²„ê¹…ìš©
            }
        }
    
    def _select_best_answer(self, answers):
        """ìµœì ì˜ ë‹µë³€ ì„ íƒ ë¡œì§"""
        if not answers:
            return "I need more information to explain this properly."
        
        # ì ì ˆí•œ ê¸¸ì´ì˜ ë‹µë³€ ì°¾ê¸° (50-400 í† í° ì •ë„)
        good_answers = []
        for ans in answers:
            ans_clean = str(ans).strip()
            word_count = len(ans_clean.split())
            if 20 <= word_count <= 150:  # ğŸ”§ í† í°ì´ ì•„ë‹Œ ë‹¨ì–´ ê¸°ì¤€ìœ¼ë¡œ ë” ë³´ìˆ˜ì 
                good_answers.append(ans_clean)
        
        if good_answers:
            return good_answers[0]
        
        # ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ë‹µë³€ì„ ì ì ˆíˆ ìë¥´ê¸°
        first_answer = str(answers[0]).strip()
        if len(first_answer.split()) > 150:
            words = first_answer.split()[:150]
            return ' '.join(words) + "..."
        
        return first_answer if first_answer else "No good answer available."
    
    def _get_default_answer(self):
        return "I need more information to explain this properly."
    
    def _is_valid_item(self, item):
        """ELI5 íŠ¹í™” ê²€ì¦ - ë” ì—„ê²©í•˜ê²Œ"""
        base_valid = super()._is_valid_item(item)
        if not base_valid:
            return False
        
        metadata = item.get('metadata', {})
        question = metadata.get('question', '')
        target = item.get('target_text', '')
        
        # ğŸ”§ FIX: ë” ì‹¤ìš©ì ì¸ ê²€ì¦
        if len(question.strip()) < 5:   # ë„ˆë¬´ ì§§ì€ ì§ˆë¬¸
            return False
        if len(target.strip()) < 20:    # ë„ˆë¬´ ì§§ì€ ë‹µë³€  
            return False
        if len(target.split()) > 200:   # ë„ˆë¬´ ê¸´ ë‹µë³€ (ë‹¨ì–´ ê¸°ì¤€)
            return False
        if "deleted" in target.lower() or "removed" in target.lower():  # ì‚­ì œëœ ë‹µë³€
            return False
            
        return True
    
    def verify_dataset_compatibility(self):
        """íŒŒì´í”„ë¼ì¸ í˜¸í™˜ì„± ê²€ì¦"""
        print(f"\nğŸ” ELI5 Pipeline Compatibility Check")
        
        if len(self.data) == 0:
            print("âŒ No data loaded!")
            return False
        
        # ì²« ë²ˆì§¸ ìƒ˜í”Œë¡œ í† í¬ë‚˜ì´ì € í…ŒìŠ¤íŠ¸
        try:
            sample = self.__getitem__(0)
            required_fields = ['input_ids', 'attention_mask', 'decoder_input_ids', 'labels', 'target_text']
            
            for field in required_fields:
                if field not in sample:
                    print(f"âŒ Missing field: {field}")
                    return False
                    
            print(f"âœ… All required fields present")
            print(f"âœ… Input length: {len(sample['input_ids'])} tokens")
            print(f"âœ… Target length: {len(sample['labels'])} tokens")
            print(f"âœ… Sample target: '{sample['target_text'][:50]}...'")
            
            return True
            
        except Exception as e:
            print(f"âŒ Tokenization failed: {e}")
            return False