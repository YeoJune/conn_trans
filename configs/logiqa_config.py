# configs/logiqa_config.py
from .base_config import BaseConfig

def get_config(model_size="micro"):
    """LogiQA Encoder-Decoder ì‹¤í—˜ìš© ì„¤ì •"""
    config = BaseConfig()
    
    # ëª¨ë¸ í¬ê¸° ì„¤ì •
    config.set_model_size(model_size)
    
    # LogiQA íŠ¹í™” ì„¤ì •
    config.update(
        dataset_name="logiqa",
        task_prefix="reason",
        
        # Encoder-Decoder ì‹œí€€ìŠ¤ ê¸¸ì´ ì„¤ì •
        max_seq_len=256 if model_size in ["tiny", "small", "base"] else 128,
        answer_max_length=16,  # A, B, C, D ë‹µë³€ì€ ì§§ìŒ
        
        # LogiQA íŠ¹í™” ì •ê·œí™”
        early_stopping_patience=3,
        eval_every=25 if model_size == "nano" else 50,
        
        # ë…¼ë¦¬ ì¶”ë¡  ìµœì í™”
        max_reasoning_steps=config.max_reasoning_steps + 1,  # ë…¼ë¦¬ ì¶”ë¡  ë‹¨ê³„ ì¦ê°€
        convergence_threshold=0.05,  # ë” ì •ë°€í•œ ìˆ˜ë ´
    )
    
    # ëª¨ë¸ ì •ë³´ ì¶œë ¥
    config.print_model_info()
    config.analyze_overfitting_risk(8027)  
    
    # Baseline í˜¸í™˜ ì„¤ì • ì¶œë ¥
    baseline_config = config.get_compatible_baseline_config()
    print(f"\nğŸ”„ Compatible Baseline Config:")
    print(f"   Encoder layers: {baseline_config['num_encoder_layers']}")
    print(f"   Decoder layers: {baseline_config['num_decoder_layers']}")
    print(f"   FFN multiplier: {baseline_config['ffn_multiplier']}")
    
    return config

