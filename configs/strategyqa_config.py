# configs/strategyqa_config.py
from .base_config import BaseConfig

def get_config(model_size="nano"):  # StrategyQAëŠ” ë°ì´í„°ê°€ ê°€ì¥ ì ì–´ì„œ nano ê¸°ë³¸
    """StrategyQA Encoder-Decoder ì‹¤í—˜ìš© ì„¤ì •"""
    config = BaseConfig()
    
    # ëª¨ë¸ í¬ê¸° ì„¤ì •
    if model_size not in ["nano", "micro"]:
        print("âš ï¸ Warning: StrategyQA ë°ì´í„°ê°€ ë§¤ìš° ì ìŠµë‹ˆë‹¤. nano ë˜ëŠ” micro ëª¨ë¸ ê¶Œì¥.")
    
    config.set_model_size(model_size)
    
    # StrategyQA íŠ¹í™” ì„¤ì •
    config.update(
        dataset_name="strategyqa",
        task_prefix="strategy",
        
        # Encoder-Decoder ì‹œí€€ìŠ¤ ê¸¸ì´ ì„¤ì •
        max_seq_len=128 if model_size in ["micro", "tiny"] else 96,
        answer_max_length=8,   # Yes, No + ê°„ë‹¨í•œ ì„¤ëª…
        
        # ê·¹ê°• ì •ê·œí™” (ë°ì´í„°ê°€ ê°€ì¥ ì ìŒ)
        dropout=0.5 if model_size == "nano" else 0.4,
        weight_decay=0.3 if model_size == "nano" else 0.2,
        learning_rate=1e-5 if model_size == "nano" else 2e-5,
        orthogonal_weight=0.2,
        
        # ë§¤ìš° ë¹ ë¥¸ ì¢…ë£Œ
        num_epochs=2,
        early_stopping_patience=2,
        eval_every=20,
        
        # Yes/No ì§ˆë¬¸ íŠ¹í™”
        label_smoothing=0.05,  # ê°„ë‹¨í•œ ë‹µë³€ì´ë¯€ë¡œ ë‚®ê²Œ
        max_reasoning_steps=max(1, config.max_reasoning_steps - 1),  # ì¶”ë¡  ë‹¨ê³„ ì¤„ì„
    )
    
    # ëª¨ë¸ ì •ë³´ ì¶œë ¥
    config.print_model_info()
    config.analyze_overfitting_risk(2780)  
    
    # Baseline í˜¸í™˜ ì„¤ì • ì¶œë ¥
    baseline_config = config.get_compatible_baseline_config()
    print(f"\nğŸ”„ Compatible Baseline Config:")
    print(f"   Encoder layers: {baseline_config['num_encoder_layers']}")
    print(f"   Decoder layers: {baseline_config['num_decoder_layers']}")
    print(f"   FFN multiplier: {baseline_config['ffn_multiplier']}")
    
    return config

