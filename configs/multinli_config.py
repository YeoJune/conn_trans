# configs/multinli_config.py
from .base_config import BaseConfig

def get_config(model_size="base"):  # MultiNLIëŠ” í° ë°ì´í„°ì…‹ì´ë¯€ë¡œ base ê¸°ë³¸
    """MultiNLI Encoder-Decoder ì‹¤í—˜ìš© ì„¤ì •"""
    config = BaseConfig()
    
    # ëª¨ë¸ í¬ê¸° ì„¤ì •
    config.set_model_size(model_size)
    
    # MultiNLI íŠ¹í™” ì„¤ì • (í° ë°ì´í„°ì…‹ì˜ ì´ì  í™œìš©)
    config.update(
        dataset_name="multinli",
        task_prefix="infer",
        
        # Encoder-Decoder ì‹œí€€ìŠ¤ ê¸¸ì´ ì„¤ì •
        max_seq_len=512 if model_size == "base" else 384,
        answer_max_length=16,  # entailment, neutral, contradiction
        
        # í° ë°ì´í„°ì…‹ì˜ ì´ì  - ì •ê·œí™” ì™„í™”
        learning_rate=1e-4 if model_size == "base" else 8e-5,
        weight_decay=0.01 if model_size == "base" else 0.05,
        dropout=0.1 if model_size == "base" else 0.2,
        orthogonal_weight=0.01 if model_size == "base" else 0.05,
        
        # ë” ë§ì€ ì—í­ ê°€ëŠ¥
        num_epochs=8 if model_size == "base" else 5,
        batch_size=32 if model_size == "base" else 16,
        gradient_accumulation_steps=2 if model_size == "base" else 4,
        
        # ì¡°ê¸° ì¢…ë£Œ ì„¤ì •
        early_stopping_patience=5,
        eval_every=500,
        
        # NLI íŠ¹í™” ìµœì í™”
        label_smoothing=0.1,
        max_reasoning_steps=config.max_reasoning_steps + 2,  # NLIëŠ” ë³µì¡í•œ ì¶”ë¡ 
    )
    
    # ëª¨ë¸ ì •ë³´ ì¶œë ¥
    config.print_model_info()
    config.analyze_overfitting_risk(433000)  
    
    # Baseline í˜¸í™˜ ì„¤ì • ì¶œë ¥
    baseline_config = config.get_compatible_baseline_config()
    print(f"\nğŸ”„ Compatible Baseline Config:")
    print(f"   Encoder layers: {baseline_config['num_encoder_layers']}")
    print(f"   Decoder layers: {baseline_config['num_decoder_layers']}")
    print(f"   FFN multiplier: {baseline_config['ffn_multiplier']}")
    
    return config
